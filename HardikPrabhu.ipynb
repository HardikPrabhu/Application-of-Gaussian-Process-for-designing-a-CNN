{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HardikPrabhu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVQNB6n3j3okltoNts/gKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HardikPrabhu/Application-of-Gaussian-Process-on-designing-a-CNN/blob/main/HardikPrabhu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YudKOguboDUS"
      },
      "source": [
        "# Application of Gaussian Process to design a CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4G2xmEmls6s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# splitting tool for the validation set\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77cpzO7ul1pO"
      },
      "source": [
        "# for visualization if needed\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZg6fPVpmFvv"
      },
      "source": [
        "#for CNN model\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense , Flatten, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCW1KeRqoiMt"
      },
      "source": [
        "Importing the files containing the dataset, Bayes optimization function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lg6EdZdYmetu",
        "outputId": "04278c05-89f3-4f91-8c2a-13f614557e46"
      },
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('gp.py','wb').write(src),\n",
        "import gp\n",
        "%load gp.py\n",
        "%run gp.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e53a152e-8789-42a8-969f-226f6240fda4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e53a152e-8789-42a8-969f-226f6240fda4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving gp.py to gp.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "v65GYuMTy2er",
        "outputId": "75bb7a4c-925f-4c53-aa40-4193b2f68385"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df385df8-5960-478b-9861-35f2e99643c8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df385df8-5960-478b-9861-35f2e99643c8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving X.npy to X.npy\n",
            "Saving Y.npy to Y.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XwuQ_DO0pcz"
      },
      "source": [
        "X = np.load(\"X.npy\")\n",
        "Y = np.load(\"Y.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8NJjNYO25w8",
        "outputId": "7a75e6fb-eecb-4db4-cc95-c4aa9e68e158"
      },
      "source": [
        "print(\" Shape of X: \",X.shape)\n",
        "print(\" Shape of Y: \",Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Shape of X:  (2062, 64, 64)\n",
            " Shape of Y:  (2062, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORUqlN-j4fKK"
      },
      "source": [
        "Input is 64x64 image.\n",
        "The total number of class labels is 10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhGSCyt77Wpb"
      },
      "source": [
        "**CNN Architecture**\n",
        "\n",
        "* We take some alternating layers of Convolution and max-pooling. The number of such layers is a hyperparameter.\n",
        "* Each convolution layer consists of some filters, the number of filters in a layer is a hyperparameter.\n",
        "* Each filter has square kernel of size nxn. \"n\" is a hyperparameter.\n",
        "* Each max-pooling layer has pool size of 2. (compresses the image by half) \n",
        "* The image is flattened and then fed to a neural network.\n",
        "* Total numer of hidden layers is a hyperparameter.\n",
        "* Neurons per layer is also another hyperparameter.\n",
        "* The final layer has 10 neurons(1 per class) with softmax activation function. Every other neuron not in the last layer has Re-Lu activation function.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_1YjsZ4_e5"
      },
      "source": [
        "def model(param):\n",
        "  #param [0]:no of cn, pooling layers. [1]:(list)filters per cn layer. [2]: (list) size of kernel per layer. [3]:no of layers in simple nn. [4]:neurons per layer \n",
        "  CNN_model = Sequential()\n",
        "  for i in range (param[0]):\n",
        "    if i == 0:\n",
        "      CNN_model.add(Conv2D(filters=param[1][i],kernel_size=(param[2][i],param[2][i]),activation=\"relu\",padding=\"same\",input_shape=((int(64/(2**i)),int(64/(2**i)),1))))\n",
        "    else:  \n",
        "      CNN_model.add(Conv2D(filters=param[1][i],kernel_size=(param[2][i],param[2][i]),activation=\"relu\",padding=\"same\",input_shape=(int(64/(2**i)),int(64/(2**i)))))\n",
        "    \n",
        "    CNN_model.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "  CNN_model.add(Flatten())\n",
        "  for i in range (param[3]): \n",
        "    CNN_model.add(Dense(param[4][i],activation=\"relu\"))\n",
        "  CNN_model.add(Dense(10,activation=\"softmax\"))\n",
        "  return CNN_model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mix3nZ89OaQS",
        "outputId": "6fc267f3-3bd6-4087-fbfa-739b210e3175"
      },
      "source": [
        "x=model([3,[16,24,12],[3,6,5],3,[32,32,16]])\n",
        "x.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 24)        13848     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 12)        7212      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 12)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                24608     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 47,582\n",
            "Trainable params: 47,582\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXdgU6h8dEww"
      },
      "source": [
        "\"x\" is an example of a network generated using the function. One of the problems with this approach is that the number of neurons per layer is a vector of size= number of layers. We simply can't have such a set of hyperparameters. So either all the layers should have the same no. of neurons(which is a hyper-parameter), or we should fix the total number of layers. We need to add certain rigidity to the structure of our network. The same goes for other parameters. To simplify things, we would assume that the simple neural network attached at the end has 3 layers. And each convolution layer has the same number of filters, and also, the same size of the kernel. With the above-mentioned compromises we define a new model generating function.( We are allowed to have different values for each variables but the number of variables should be fixed.) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjEX2KRphWC6"
      },
      "source": [
        "def model_gen(param):\n",
        "  #param [0]:no of cn, pooling layers. [1]:filters per cn layer. [2]:size of kernel for each filter  [3]:neurons per layer in the simple 3 layered nn at back  \n",
        "  CNN_model = Sequential()\n",
        "  for i in range (param[0]):\n",
        "    if i == 0:\n",
        "      CNN_model.add(Conv2D(filters=param[1],kernel_size=(param[2],param[2]),activation=\"relu\",padding=\"same\",input_shape=((int(64/(2**i)),int(64/(2**i)),1))))\n",
        "    else:  \n",
        "      CNN_model.add(Conv2D(filters=param[1],kernel_size=(param[2],param[2]),activation=\"relu\",padding=\"same\",input_shape=(int(64/(2**i)),int(64/(2**i)))))\n",
        "    \n",
        "    CNN_model.add(MaxPooling2D(pool_size=(2,2),padding=\"same\"))\n",
        "  CNN_model.add(Flatten())\n",
        "  for i in range (3): \n",
        "    CNN_model.add(Dense(param[3][i],activation=\"relu\"))\n",
        "  CNN_model.add(Dense(10,activation=\"softmax\"))\n",
        "  return CNN_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVQV6gLelIWn"
      },
      "source": [
        "ad_hoc=model_gen([2,16,3,[16,16,16]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30KXZOJKlgZC",
        "outputId": "c7f61094-9b8e-4588-9902-c8bfeb77fe06"
      },
      "source": [
        "ad_hoc.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 16)                65552     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 68,746\n",
            "Trainable params: 68,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGCINzdXl3DL"
      },
      "source": [
        "We will use the above network to compare the accuracy with the final tuning of the hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ni7LL6pS_T"
      },
      "source": [
        "#spliting train-test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "x_train = x_train.reshape(-1,64,64,1)\n",
        "x_test = x_test.reshape(-1,64,64,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSEcLiDlvuSP",
        "outputId": "9a71cd5d-cad0-4c4f-8149-67f991f27144"
      },
      "source": [
        "ad_hoc.compile(optimizer=Adam(lr=0.002),loss=keras.losses.categorical_crossentropy,metrics=[\"accuracy\"])\n",
        "results = ad_hoc.fit(x_train,y_train,epochs=15,validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "37/37 [==============================] - 3s 88ms/step - loss: 2.3041 - accuracy: 0.0936 - val_loss: 2.3043 - val_accuracy: 0.1030\n",
            "Epoch 2/15\n",
            "37/37 [==============================] - 3s 83ms/step - loss: 2.3027 - accuracy: 0.1023 - val_loss: 2.3044 - val_accuracy: 0.1172\n",
            "Epoch 3/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 2.3023 - accuracy: 0.1092 - val_loss: 2.3139 - val_accuracy: 0.0929\n",
            "Epoch 4/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 2.3000 - accuracy: 0.1057 - val_loss: 2.3005 - val_accuracy: 0.0970\n",
            "Epoch 5/15\n",
            "37/37 [==============================] - 3s 86ms/step - loss: 2.2849 - accuracy: 0.1482 - val_loss: 2.3009 - val_accuracy: 0.0929\n",
            "Epoch 6/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 2.2202 - accuracy: 0.1560 - val_loss: 2.2244 - val_accuracy: 0.1737\n",
            "Epoch 7/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 2.1488 - accuracy: 0.1924 - val_loss: 2.1857 - val_accuracy: 0.1717\n",
            "Epoch 8/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 2.0923 - accuracy: 0.1976 - val_loss: 2.1327 - val_accuracy: 0.2101\n",
            "Epoch 9/15\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 2.0484 - accuracy: 0.1906 - val_loss: 2.0744 - val_accuracy: 0.2101\n",
            "Epoch 10/15\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 1.9841 - accuracy: 0.2002 - val_loss: 2.0092 - val_accuracy: 0.2202\n",
            "Epoch 11/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 1.9032 - accuracy: 0.2166 - val_loss: 2.0480 - val_accuracy: 0.1960\n",
            "Epoch 12/15\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 1.8764 - accuracy: 0.2504 - val_loss: 2.4086 - val_accuracy: 0.1535\n",
            "Epoch 13/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 1.8708 - accuracy: 0.2660 - val_loss: 1.8422 - val_accuracy: 0.2606\n",
            "Epoch 14/15\n",
            "37/37 [==============================] - 3s 84ms/step - loss: 1.7510 - accuracy: 0.3024 - val_loss: 1.8623 - val_accuracy: 0.2343\n",
            "Epoch 15/15\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 1.7055 - accuracy: 0.3120 - val_loss: 1.7743 - val_accuracy: 0.2545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngdqHgYtuHGW",
        "outputId": "4ac50343-da84-4272-de9c-e821f5f878ac"
      },
      "source": [
        "ad_hoc.evaluate(x_test,y_test)[1] #accuracy over test set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 26ms/step - loss: 1.7032 - accuracy: 0.2857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2857142984867096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2TEEL-eyitt"
      },
      "source": [
        "Clearly, we could do better at 15th epoch, as the accuracy is really poor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25mr0PwzSSZ"
      },
      "source": [
        "Before we apply Bayesian Optimization, lets further split training data into training and validation. That way we can compute loss function as the accuracy over the validation set while tuning the hyperparameters using bayes optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rB8I-6i0Zzi"
      },
      "source": [
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.3,random_state=42)\n",
        "x_train = x_train.reshape(-1,64,64,1)\n",
        "x_val = x_val.reshape(-1,64,64,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9mEEyNPzo3R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xslSRIxKmzCP"
      },
      "source": [
        "**Bayesian Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIqk8dLwmT2_"
      },
      "source": [
        "#define the loss function\n",
        "\n",
        "def sample_loss(params):  #list of parameters\n",
        "  model=model_gen([int(params[0]),int(params[1]),int(params[2]),[int(params[3]),int(params[4]),int(params[5])]])\n",
        "  model.compile(optimizer=Adam(lr=0.002),loss=keras.losses.categorical_crossentropy,metrics=[\"accuracy\"])\n",
        "  result=model.fit(x_train,y_train,epochs=15)\n",
        "  return model.evaluate(x_val,y_val)[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1G-pP517HQA"
      },
      "source": [
        "**Define the boundary**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHYim05P7TJH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdK03Vgn6RgR"
      },
      "source": [
        "bounds=np.array([[2,5],[15,64],[2,5],[10,60],[10,60],[10,60]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-Fr80s5_RpH",
        "outputId": "3779d485-cf5a-443f-e4a8-c1793613f274"
      },
      "source": [
        "xp,yp=bayesian_optimisation(n_iters=20,sample_loss=sample_loss,bounds=bounds,n_pre_samples=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 2.3052 - accuracy: 0.1016\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.3022 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.3012 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 2.2992 - accuracy: 0.1202\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 2.1013 - accuracy: 0.2057\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 1.2173 - accuracy: 0.5836\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.7437 - accuracy: 0.7534\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.6431 - accuracy: 0.7856\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.5493 - accuracy: 0.7993\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 0.4254 - accuracy: 0.8612\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.3084 - accuracy: 0.9033\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.2168 - accuracy: 0.9343\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.2102 - accuracy: 0.9306\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.1648 - accuracy: 0.9368\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.5018 - accuracy: 0.8501\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 6s 223ms/step - loss: 2.3081 - accuracy: 0.0880\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 6s 219ms/step - loss: 2.3027 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3020 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3016 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3011 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 6s 220ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3007 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 6s 217ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 6s 219ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 6s 219ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 6s 217ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 6s 218ms/step - loss: 2.2998 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 2.3053 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 8s 311ms/step - loss: 2.3069 - accuracy: 0.0929\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 8s 306ms/step - loss: 2.3023 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 8s 307ms/step - loss: 2.3027 - accuracy: 0.1103\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 8s 305ms/step - loss: 2.3011 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 2.2267 - accuracy: 0.1512\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 1.5642 - accuracy: 0.4287\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 1.0491 - accuracy: 0.6468\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 0.7604 - accuracy: 0.7447\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 8s 306ms/step - loss: 0.6080 - accuracy: 0.7931\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 8s 307ms/step - loss: 0.4327 - accuracy: 0.8724\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 0.3342 - accuracy: 0.9058\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 8s 307ms/step - loss: 0.2554 - accuracy: 0.9269\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 8s 309ms/step - loss: 0.2245 - accuracy: 0.9318\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 8s 308ms/step - loss: 0.1512 - accuracy: 0.9554\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 8s 307ms/step - loss: 0.1635 - accuracy: 0.9418\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 0.4620 - accuracy: 0.8617\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 4s 170ms/step - loss: 2.3077 - accuracy: 0.1041\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3031 - accuracy: 0.1078\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3018 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.3012 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 4s 169ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.2999 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 2.3058 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 130ms/step - loss: 2.3042 - accuracy: 0.1066\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 129ms/step - loss: 2.3022 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 130ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 131ms/step - loss: 2.2994 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 131ms/step - loss: 2.2458 - accuracy: 0.1276\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 130ms/step - loss: 1.8178 - accuracy: 0.3234\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 132ms/step - loss: 1.2884 - accuracy: 0.5105\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 132ms/step - loss: 0.9443 - accuracy: 0.6543\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 131ms/step - loss: 0.7299 - accuracy: 0.7410\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 131ms/step - loss: 0.5891 - accuracy: 0.8067\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 132ms/step - loss: 0.5238 - accuracy: 0.8278\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 131ms/step - loss: 0.5370 - accuracy: 0.8228\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 132ms/step - loss: 0.3557 - accuracy: 0.8922\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 0.2770 - accuracy: 0.9182\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 0.2355 - accuracy: 0.9380\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.6901 - accuracy: 0.7954\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 7s 258ms/step - loss: 2.3083 - accuracy: 0.1066\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 7s 254ms/step - loss: 2.3024 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 7s 256ms/step - loss: 2.3011 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 7s 255ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 7s 255ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 7s 255ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 7s 254ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 7s 253ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 7s 257ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 7s 257ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 7s 254ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 7s 255ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 7s 254ms/step - loss: 2.3006 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 7s 253ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 7s 253ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 2.3067 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 2.3058 - accuracy: 0.0905\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.3023 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.3015 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.2987 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.2112 - accuracy: 0.1524\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 1.9856 - accuracy: 0.2342\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 1.8591 - accuracy: 0.2689\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 1.5834 - accuracy: 0.3928\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 1.4565 - accuracy: 0.4511\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 1.2963 - accuracy: 0.5378\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 1.1885 - accuracy: 0.5688\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 10s 385ms/step - loss: 1.0816 - accuracy: 0.6283\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 0.9937 - accuracy: 0.6530\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 1.0913 - accuracy: 0.6427\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 2.3046 - accuracy: 0.0632\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 2.2985 - accuracy: 0.1239\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 2.2254 - accuracy: 0.2069\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 120ms/step - loss: 1.9170 - accuracy: 0.2491\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 1.5243 - accuracy: 0.4944\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 1.1833 - accuracy: 0.5923\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.9693 - accuracy: 0.6865\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 121ms/step - loss: 0.7945 - accuracy: 0.7497\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.7550 - accuracy: 0.7299\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.5732 - accuracy: 0.8141\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 120ms/step - loss: 0.5255 - accuracy: 0.8203\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 120ms/step - loss: 0.4135 - accuracy: 0.8563\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 120ms/step - loss: 0.3636 - accuracy: 0.8848\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.2644 - accuracy: 0.9170\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 3s 120ms/step - loss: 0.2254 - accuracy: 0.9306\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6914 - accuracy: 0.8040\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 2.3088 - accuracy: 0.1041\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 2.3029 - accuracy: 0.0991\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 2.3013 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 2.2989 - accuracy: 0.1078\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 2.1124 - accuracy: 0.2069\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 1.5862 - accuracy: 0.4077\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 1.2144 - accuracy: 0.5613\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 5s 175ms/step - loss: 0.9619 - accuracy: 0.6382\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 0.7727 - accuracy: 0.7162\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 5s 174ms/step - loss: 0.6592 - accuracy: 0.7658\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 0.5367 - accuracy: 0.8141\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 5s 178ms/step - loss: 0.4328 - accuracy: 0.8501\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 5s 177ms/step - loss: 0.3245 - accuracy: 0.8848\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 5s 176ms/step - loss: 0.3088 - accuracy: 0.8959\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 0.4497 - accuracy: 0.8444\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 2.3048 - accuracy: 0.0942\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 2.3014 - accuracy: 0.0942\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 2.3004 - accuracy: 0.1029\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 2.2801 - accuracy: 0.1351\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 2.0994 - accuracy: 0.2429\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 1.7046 - accuracy: 0.3717\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 1.4795 - accuracy: 0.4325\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 1.2852 - accuracy: 0.4969\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1271 - accuracy: 0.5849\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 1.0012 - accuracy: 0.6307\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8732 - accuracy: 0.7113\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8060 - accuracy: 0.7014\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7054 - accuracy: 0.7447\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7163 - accuracy: 0.7423\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6027 - accuracy: 0.7732\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.7625 - accuracy: 0.7378\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 2.3061 - accuracy: 0.0954\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 6s 236ms/step - loss: 2.3020 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 6s 237ms/step - loss: 2.3007 - accuracy: 0.1066\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 2.2039 - accuracy: 0.1400\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 6s 238ms/step - loss: 1.6178 - accuracy: 0.3742\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 6s 239ms/step - loss: 1.1332 - accuracy: 0.5613\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 6s 239ms/step - loss: 0.8267 - accuracy: 0.6964\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 6s 240ms/step - loss: 0.5888 - accuracy: 0.8141\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 6s 240ms/step - loss: 0.4718 - accuracy: 0.8352\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 6s 241ms/step - loss: 0.3999 - accuracy: 0.8711\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 6s 242ms/step - loss: 0.3451 - accuracy: 0.8984\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 6s 242ms/step - loss: 0.2081 - accuracy: 0.9393\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 6s 242ms/step - loss: 0.1764 - accuracy: 0.9455\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 6s 243ms/step - loss: 0.1135 - accuracy: 0.9752\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 6s 243ms/step - loss: 0.0784 - accuracy: 0.9777\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.4554 - accuracy: 0.8674\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 2.3043 - accuracy: 0.0805\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 2s 66ms/step - loss: 2.3027 - accuracy: 0.0979\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 2.3016 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 2.3013 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 2.3007 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 2s 66ms/step - loss: 2.2995 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 2.2747 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.9990 - accuracy: 0.2206\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 2s 69ms/step - loss: 1.7977 - accuracy: 0.2751\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.6362 - accuracy: 0.3346\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 2s 67ms/step - loss: 1.6225 - accuracy: 0.3321\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.4495 - accuracy: 0.4238\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.3358 - accuracy: 0.4783\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.2049 - accuracy: 0.5068\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 2s 68ms/step - loss: 1.2130 - accuracy: 0.5043\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.1542 - accuracy: 0.5706\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 10s 391ms/step - loss: 2.3074 - accuracy: 0.1016\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.3020 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 2.3011 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.3026 - accuracy: 0.1078\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 10s 392ms/step - loss: 2.2995 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 2.2370 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.1173 - accuracy: 0.1599\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 10s 387ms/step - loss: 2.0279 - accuracy: 0.1772\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 1.9740 - accuracy: 0.2206\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 1.9567 - accuracy: 0.2181\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 10s 392ms/step - loss: 1.8404 - accuracy: 0.2466\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 10s 389ms/step - loss: 1.7947 - accuracy: 0.2664\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 1.7247 - accuracy: 0.2763\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 1.6700 - accuracy: 0.3036\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 1.6630 - accuracy: 0.2680\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 2s 83ms/step - loss: 2.3099 - accuracy: 0.0991\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 2s 83ms/step - loss: 2.2989 - accuracy: 0.1363\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 2.2215 - accuracy: 0.2156\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 1.7425 - accuracy: 0.3817\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 2s 83ms/step - loss: 1.1977 - accuracy: 0.5799\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 2s 85ms/step - loss: 1.0694 - accuracy: 0.6121\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.8161 - accuracy: 0.7224\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 2s 83ms/step - loss: 0.6811 - accuracy: 0.7633\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.5962 - accuracy: 0.7980\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.5233 - accuracy: 0.8265\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 2s 85ms/step - loss: 0.4016 - accuracy: 0.8773\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.3305 - accuracy: 0.8996\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.2995 - accuracy: 0.9157\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.2585 - accuracy: 0.9170\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 2s 84ms/step - loss: 0.1793 - accuracy: 0.9430\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.7996 - accuracy: 0.7810\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3056 - accuracy: 0.0942\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3023 - accuracy: 0.1090\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.3018 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3012 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3010 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 2.3013 - accuracy: 0.0942\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.3008 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 2s 72ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.2999 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 2s 73ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 2s 74ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 2.3051 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 2.3040 - accuracy: 0.1016\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 4s 139ms/step - loss: 2.3022 - accuracy: 0.1029\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 4s 139ms/step - loss: 2.3016 - accuracy: 0.1078\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 2.3011 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 4s 139ms/step - loss: 2.3005 - accuracy: 0.1103\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 2.2956 - accuracy: 0.1375\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 2.2188 - accuracy: 0.1475\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 1.9756 - accuracy: 0.2268\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.7857 - accuracy: 0.2726\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.5902 - accuracy: 0.3755\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 1.5398 - accuracy: 0.4523\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 139ms/step - loss: 1.4546 - accuracy: 0.4411\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 1.2225 - accuracy: 0.5353\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 1.1009 - accuracy: 0.5824\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 0.9557 - accuracy: 0.6431\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 1.1155 - accuracy: 0.5331\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 2.3080 - accuracy: 0.0892\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 2.2661 - accuracy: 0.1673\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 4s 146ms/step - loss: 1.8929 - accuracy: 0.3061\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 1.3021 - accuracy: 0.5217\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 1.0467 - accuracy: 0.6159\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 0.9586 - accuracy: 0.6617\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 0.8480 - accuracy: 0.6766\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 146ms/step - loss: 0.7605 - accuracy: 0.7311\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 147ms/step - loss: 0.6928 - accuracy: 0.7584\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 147ms/step - loss: 0.6173 - accuracy: 0.7943\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 147ms/step - loss: 0.5509 - accuracy: 0.8104\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 146ms/step - loss: 0.5107 - accuracy: 0.8265\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 146ms/step - loss: 0.4694 - accuracy: 0.8439\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 0.4262 - accuracy: 0.8649\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.6657 - accuracy: 0.7810\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 5s 184ms/step - loss: 2.3095 - accuracy: 0.0954\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 5s 184ms/step - loss: 2.2690 - accuracy: 0.1388\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 5s 184ms/step - loss: 2.0257 - accuracy: 0.2305\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 1.5761 - accuracy: 0.4114\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 5s 185ms/step - loss: 1.1115 - accuracy: 0.6208\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 5s 185ms/step - loss: 0.9075 - accuracy: 0.7063\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 5s 184ms/step - loss: 0.7362 - accuracy: 0.7447\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 5s 187ms/step - loss: 0.5937 - accuracy: 0.8166\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 5s 185ms/step - loss: 0.5550 - accuracy: 0.8191\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 0.4784 - accuracy: 0.8513\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 0.4085 - accuracy: 0.8674\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 0.3799 - accuracy: 0.8686\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 0.3133 - accuracy: 0.9021\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 5s 185ms/step - loss: 0.2578 - accuracy: 0.9257\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 5s 186ms/step - loss: 0.2451 - accuracy: 0.9244\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.6849 - accuracy: 0.7896\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 2.3077 - accuracy: 0.1053\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 2.2701 - accuracy: 0.1735\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 1.8601 - accuracy: 0.3532\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 1.3766 - accuracy: 0.5006\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.9969 - accuracy: 0.6456\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.8747 - accuracy: 0.7051\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 0.7723 - accuracy: 0.7509\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.6555 - accuracy: 0.7732\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.4861 - accuracy: 0.8550\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 117ms/step - loss: 0.5227 - accuracy: 0.8240\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.4384 - accuracy: 0.8625\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 119ms/step - loss: 0.3395 - accuracy: 0.8934\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.3566 - accuracy: 0.8761\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.2783 - accuracy: 0.9182\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 3s 118ms/step - loss: 0.2857 - accuracy: 0.9009\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.6471 - accuracy: 0.8184\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 11s 438ms/step - loss: 2.3072 - accuracy: 0.1029\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 11s 437ms/step - loss: 2.3022 - accuracy: 0.1066\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 12s 451ms/step - loss: 2.3016 - accuracy: 0.1066\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 12s 444ms/step - loss: 2.3015 - accuracy: 0.1066\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 11s 434ms/step - loss: 2.3010 - accuracy: 0.1078\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 11s 434ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 11s 435ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 11s 434ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 11s 435ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 11s 435ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 11s 435ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 11s 437ms/step - loss: 2.2999 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 11s 438ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 11s 436ms/step - loss: 2.2998 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 11s 435ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.3065 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 2.3052 - accuracy: 0.0843\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 2.3024 - accuracy: 0.0905\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 111ms/step - loss: 2.3015 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 2.2996 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 111ms/step - loss: 2.1493 - accuracy: 0.1760\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 1.4560 - accuracy: 0.4709\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 1.0189 - accuracy: 0.6518\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 112ms/step - loss: 0.8145 - accuracy: 0.7100\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 113ms/step - loss: 0.6428 - accuracy: 0.7906\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 114ms/step - loss: 0.5274 - accuracy: 0.8315\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 114ms/step - loss: 0.4440 - accuracy: 0.8649\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 115ms/step - loss: 0.3483 - accuracy: 0.8934\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 111ms/step - loss: 0.3329 - accuracy: 0.8934\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 3s 111ms/step - loss: 0.2860 - accuracy: 0.9095\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4882 - accuracy: 0.8386\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 5s 191ms/step - loss: 2.3049 - accuracy: 0.0892\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 5s 190ms/step - loss: 2.3015 - accuracy: 0.1041\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 5s 190ms/step - loss: 2.3012 - accuracy: 0.1053\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 5s 191ms/step - loss: 2.3006 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 5s 194ms/step - loss: 2.3002 - accuracy: 0.0892\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 5s 193ms/step - loss: 2.2529 - accuracy: 0.1066\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 5s 193ms/step - loss: 2.1366 - accuracy: 0.1784\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 5s 192ms/step - loss: 2.0264 - accuracy: 0.1797\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 5s 192ms/step - loss: 1.8623 - accuracy: 0.2454\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 5s 192ms/step - loss: 1.7046 - accuracy: 0.2924\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 5s 191ms/step - loss: 1.6366 - accuracy: 0.3086\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 5s 193ms/step - loss: 1.5173 - accuracy: 0.3891\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 5s 192ms/step - loss: 1.3994 - accuracy: 0.4622\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 5s 190ms/step - loss: 1.3191 - accuracy: 0.4857\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 5s 192ms/step - loss: 1.1968 - accuracy: 0.5167\n",
            "11/11 [==============================] - 1s 60ms/step - loss: 1.3182 - accuracy: 0.4553\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 2.3051 - accuracy: 0.0905\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 2.2853 - accuracy: 0.1128\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 2.0391 - accuracy: 0.2540\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.5691 - accuracy: 0.3928\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.1928 - accuracy: 0.5799\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9266 - accuracy: 0.6964\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7236 - accuracy: 0.7621\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5826 - accuracy: 0.8104\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4613 - accuracy: 0.8253\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4459 - accuracy: 0.8501\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.3484 - accuracy: 0.8736\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.2822 - accuracy: 0.9232\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.2506 - accuracy: 0.9182\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.2022 - accuracy: 0.9294\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.1753 - accuracy: 0.9467\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.6976 - accuracy: 0.8040\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 7s 271ms/step - loss: 2.3067 - accuracy: 0.0818\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3022 - accuracy: 0.1115\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 7s 271ms/step - loss: 2.3012 - accuracy: 0.1004\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3006 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3009 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3004 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3006 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 7s 270ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 7s 271ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 7s 272ms/step - loss: 2.3006 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 7s 272ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 7s 272ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 7s 271ms/step - loss: 2.3000 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 7s 272ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 2.3068 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 4s 164ms/step - loss: 2.3075 - accuracy: 0.1078\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 2.2374 - accuracy: 0.1871\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 1.8760 - accuracy: 0.3011\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 1.4540 - accuracy: 0.4424\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 1.1253 - accuracy: 0.5936\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 0.8238 - accuracy: 0.7311\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 0.6520 - accuracy: 0.7931\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 0.5233 - accuracy: 0.8166\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 0.4348 - accuracy: 0.8463\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 166ms/step - loss: 0.4801 - accuracy: 0.8253\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 169ms/step - loss: 0.3125 - accuracy: 0.9009\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 169ms/step - loss: 0.2179 - accuracy: 0.9418\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 168ms/step - loss: 0.1575 - accuracy: 0.9566\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 0.1314 - accuracy: 0.9628\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 167ms/step - loss: 0.1269 - accuracy: 0.9641\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.8688 - accuracy: 0.7781\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3095 - accuracy: 0.1041\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.3020 - accuracy: 0.1016\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3015 - accuracy: 0.1140\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.3015 - accuracy: 0.1140\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.3010 - accuracy: 0.1140\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3007 - accuracy: 0.1140\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3005 - accuracy: 0.1140\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3003 - accuracy: 0.1140\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 2.2999 - accuracy: 0.1140\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 2.2999 - accuracy: 0.1140\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 8s 318ms/step - loss: 2.3001 - accuracy: 0.1140\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.3061 - accuracy: 0.1124\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 2.3108 - accuracy: 0.1004\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 100ms/step - loss: 2.2921 - accuracy: 0.1301\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 101ms/step - loss: 2.1949 - accuracy: 0.1995\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 1.8916 - accuracy: 0.3556\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 1.5720 - accuracy: 0.4672\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 1.3456 - accuracy: 0.5514\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 101ms/step - loss: 1.1245 - accuracy: 0.6134\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 1.1202 - accuracy: 0.6084\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 101ms/step - loss: 0.9563 - accuracy: 0.6704\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 0.9053 - accuracy: 0.6902\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 0.8903 - accuracy: 0.6964\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 0.7297 - accuracy: 0.7633\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 0.6456 - accuracy: 0.7881\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 102ms/step - loss: 0.6325 - accuracy: 0.7893\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 3s 103ms/step - loss: 0.5721 - accuracy: 0.8203\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 1.0279 - accuracy: 0.7089\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 126ms/step - loss: 2.3081 - accuracy: 0.0805\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 126ms/step - loss: 2.3012 - accuracy: 0.1066\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 125ms/step - loss: 2.2615 - accuracy: 0.1574\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 124ms/step - loss: 1.9489 - accuracy: 0.2763\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 125ms/step - loss: 1.5682 - accuracy: 0.3990\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 3s 125ms/step - loss: 1.1600 - accuracy: 0.5985\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 127ms/step - loss: 0.9370 - accuracy: 0.6506\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 124ms/step - loss: 0.8115 - accuracy: 0.6865\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 3s 125ms/step - loss: 0.7378 - accuracy: 0.7546\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 3s 126ms/step - loss: 0.5040 - accuracy: 0.8439\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 3s 126ms/step - loss: 0.4554 - accuracy: 0.8538\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 3s 127ms/step - loss: 0.4021 - accuracy: 0.8674\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 3s 125ms/step - loss: 0.3167 - accuracy: 0.9058\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 3s 126ms/step - loss: 0.2728 - accuracy: 0.9207\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 3s 127ms/step - loss: 0.1998 - accuracy: 0.9442\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.4988 - accuracy: 0.8300\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 2.3059 - accuracy: 0.0991\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 3s 132ms/step - loss: 2.3028 - accuracy: 0.0942\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 3s 134ms/step - loss: 2.3020 - accuracy: 0.0991\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 2.3012 - accuracy: 0.0967\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 2.3003 - accuracy: 0.1078\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 2.2713 - accuracy: 0.1301\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 1.9559 - accuracy: 0.2119\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 3s 133ms/step - loss: 1.8131 - accuracy: 0.2565\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 1.5396 - accuracy: 0.4362\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 1.2375 - accuracy: 0.5328\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 1.0218 - accuracy: 0.6047\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 4s 136ms/step - loss: 0.8886 - accuracy: 0.6592\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 4s 135ms/step - loss: 0.7772 - accuracy: 0.7200\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 4s 136ms/step - loss: 0.6013 - accuracy: 0.8005\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 4s 137ms/step - loss: 0.5545 - accuracy: 0.8191\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.7123 - accuracy: 0.7608\n",
            "Epoch 1/15\n",
            "26/26 [==============================] - 8s 298ms/step - loss: 2.3076 - accuracy: 0.1029\n",
            "Epoch 2/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 2.3043 - accuracy: 0.0892\n",
            "Epoch 3/15\n",
            "26/26 [==============================] - 8s 298ms/step - loss: 2.3013 - accuracy: 0.1078\n",
            "Epoch 4/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 2.2993 - accuracy: 0.1214\n",
            "Epoch 5/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 2.1498 - accuracy: 0.1797\n",
            "Epoch 6/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 1.4549 - accuracy: 0.4734\n",
            "Epoch 7/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 1.0043 - accuracy: 0.6431\n",
            "Epoch 8/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 0.6566 - accuracy: 0.7819\n",
            "Epoch 9/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 0.5412 - accuracy: 0.8253\n",
            "Epoch 10/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 0.4306 - accuracy: 0.8674\n",
            "Epoch 11/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 0.2926 - accuracy: 0.9009\n",
            "Epoch 12/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 0.2560 - accuracy: 0.9195\n",
            "Epoch 13/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 0.2039 - accuracy: 0.9405\n",
            "Epoch 14/15\n",
            "26/26 [==============================] - 8s 296ms/step - loss: 0.1619 - accuracy: 0.9616\n",
            "Epoch 15/15\n",
            "26/26 [==============================] - 8s 297ms/step - loss: 0.1065 - accuracy: 0.9789\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.4481 - accuracy: 0.8646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpPmwUQbQHmx",
        "outputId": "46e54c3c-b26a-49e6-cdc3-fd52c28a706e"
      },
      "source": [
        "xphat=np.round(xp[np.array(yp).argmax(),:])\n",
        "print(xphat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4. 37.  5. 36. 29. 31.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blTd5tCpReuD"
      },
      "source": [
        "These are the hyper-parameters given by our optimization algorithm. We should now check whether a model trained with these parameters perform significantly better than the previously randomly constructed model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YEagfYxUc3E",
        "outputId": "632c465a-54e6-4b6a-ba8f-4007f1e93e70"
      },
      "source": [
        "final_model=model_gen([4,37,5,[36,29,31]])\n",
        "final_model.compile(optimizer=Adam(lr=0.002),loss=keras.losses.categorical_crossentropy,metrics=[\"accuracy\"])\n",
        "results2 =final_model.fit(x_train,y_train,epochs=15)\n",
        "final_model.evaluate(x_test,y_test)[1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 2.3053 - accuracy: 0.0936\n",
            "Epoch 2/15\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 2.3011 - accuracy: 0.1135\n",
            "Epoch 3/15\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 2.2936 - accuracy: 0.1231\n",
            "Epoch 4/15\n",
            "37/37 [==============================] - 15s 406ms/step - loss: 1.9504 - accuracy: 0.2972\n",
            "Epoch 5/15\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 1.1856 - accuracy: 0.6014\n",
            "Epoch 6/15\n",
            "37/37 [==============================] - 15s 407ms/step - loss: 0.8157 - accuracy: 0.7314\n",
            "Epoch 7/15\n",
            "37/37 [==============================] - 15s 409ms/step - loss: 0.5662 - accuracy: 0.8102\n",
            "Epoch 8/15\n",
            "37/37 [==============================] - 15s 409ms/step - loss: 0.3428 - accuracy: 0.8891\n",
            "Epoch 9/15\n",
            "37/37 [==============================] - 15s 407ms/step - loss: 0.3114 - accuracy: 0.9038\n",
            "Epoch 10/15\n",
            "37/37 [==============================] - 15s 408ms/step - loss: 0.3945 - accuracy: 0.8588\n",
            "Epoch 11/15\n",
            "37/37 [==============================] - 15s 407ms/step - loss: 0.1520 - accuracy: 0.9575\n",
            "Epoch 12/15\n",
            "37/37 [==============================] - 15s 409ms/step - loss: 0.1249 - accuracy: 0.9662\n",
            "Epoch 13/15\n",
            "37/37 [==============================] - 15s 410ms/step - loss: 0.0738 - accuracy: 0.9827\n",
            "Epoch 14/15\n",
            "37/37 [==============================] - 15s 407ms/step - loss: 0.0806 - accuracy: 0.9766\n",
            "Epoch 15/15\n",
            "37/37 [==============================] - 15s 407ms/step - loss: 0.0406 - accuracy: 0.9922\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.2696 - accuracy: 0.9249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9249394536018372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXUpdTLnXFx4"
      },
      "source": [
        "After hyper-parameter tuning using Bayesian optimization for 20 iterations, the accuracy over the test dataset is 0.92 which is significantly better than random hyper-parameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDwXqutlXlrT"
      },
      "source": [
        ""
      ]
    }
  ]
}